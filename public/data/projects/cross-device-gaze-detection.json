{
  "id": "cross-device-gaze-detection",
  "title": "Cross-Device Gaze Detection for At-Home Attention",
  "description": "Developed cross-device gaze estimation models for mobile, desktop, and TV, reducing error from 50 mm to under 30 mm and powering large-scale visual attention analytics.",
  "longDescription": "This project unified gaze-tracking research across multiple device form factors to measure human attention with precision and privacy. Traditional gaze models often degrade when moving between mobile, desktop, and TV contexts due to differing optics, distance, and lighting. The solution involved domain-adaptive architectures combining convolutional and transformer-based encoders, trained with custom loss functions to counter regression-to-mean. A dataset of more than 5,000 participants was collected, covering diverse viewing environments and screen geometries. The resulting cross-device gaze engine achieved sub-30 mm accuracy and processed 34 million live views in real time, enabling data-driven creative insights and ethical, privacy-first attention measurement at scale.",
  "technologies": [
    "Python",
    "PyTorch",
    "TensorFlow Lite",
    "ONNX",
    "CNNs",
    "Vision Transformers",
    "Data Augmentation",
    "Gaze Estimation"
  ],
  "status": "completed",
  "featured": true,
  "images": ["/images/illustrations/cross_device_gaze.webp"],
  "demoUrl": "",
  "githubUrl": "",
  "startDate": "2022-03-01",
  "endDate": "2024-01-30",
  "outcomes": [
    "Reduced gaze error from ~50 mm â†’ < 30 mm across devices",
    "Processed 11B+ live attention samples in production",
    "Supported 63 formats, 19 platforms, 16 countries in deployment",
    "1.3M+ human subjects participated in the dataset collection"
  ],
  "challenge": "Device-specific differences in camera position, user distance, and lighting cause large performance gaps in gaze-tracking models. Building a unified model that generalizes across phones, TVs, and desktops without compromising accuracy or privacy was critical for real-world adoption.",
  "solution": "Developed a multimodal gaze-estimation architecture blending CNN and ViT encoders with domain adaptation layers. Introduced novel loss functions to stabilize regression and trained on a cross-device dataset of 1.3M+ participants. Deployed a 4K real-time pipeline sustaining 8K QPS at 360 MB/s throughput using TFLite and ONNX quantization. Combined edge inference and anonymized telemetry to maintain privacy and global performance consistency.",
  "results": "Delivered reliable cross-device gaze estimation wit h < 30 mm error margin, producing 85 % F1 score in attention prediction. Processed 34 million live views and generated millions in ARR for attention analytics products while upholding strict privacy and compliance standards.",
  "technicalHighlights": [
    "Unified gaze-estimation pipeline for mobile, desktop, and TV contexts",
    "Custom loss functions correcting regression-to-mean in hybrid CNN + ViT models",
    "4K real-time inference at 8K QPS and 360 MB/s throughput",
    "Cross-device calibration using geometric normalization and domain adaptation",
    "Integrated privacy-safe telemetry ensuring compliant attention analytics"
  ]
}
